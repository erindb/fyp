<!DOCTYPE html>

<html>
<head>
  <link rel="stylesheet" href="../css/genericExperiment.css" />
  <style>
  	#debriefWriteup { display: block; text-align: left; }
  	#debriefWriteup > p { width: 650px; }
    .graph { text-align: center; }
    img { display: inline-block; margin: 20px; }
    #waiter { width: 200px; }
    #customer { width: 150px; }
   </style>
</head>
<body>
<div class='slide' id='debriefWriteup'>
<p>Recently, people have been working on making programs that are able able to extract general commonsense knowledge from text. For example, <a href='//www.aclweb.org/anthology/S/S15/S15-1.pdf#page=223'>this paper</a> learns about restaurants from <a href='http://www.dinnersfromhell.com/'>blog posts</a>. These programs are often evaluated on a task very similar to the one you just performed.</p>
<p>We want to know how people perform on tasks like this. Do they tend to agree with one another? Do their guesses tend to match the original text? For which stories do the computer programs give similar answers to people? When do they give different answers?</p>
<p>If you have questions about this research, please contact Erin Bennett at <a href="mailto://erindb@stanford.edu">erindb@stanford.edu</a> or Noah Goodman, at ngoodman@stanford.edu.</p>
<p>Here are some examples of restaurant scripts (for waiters and customers) that these models might be able to learn:</p>
<p class='graph'><img id='waiter' src='../images/waiter.svg'/><img id='customer' src='../images/customer.svg'/></p>
</div>
</body>
</html>