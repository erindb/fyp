---
title: "Narrative Cloze Task: Experiment 1"
author: |
  | Erin Bennett
  | `erindb@stanford.edu`
bibliography: ../bibliography.bib
output:
  pdf_document:
    toc: false
    highlight: zenburn
    toc_depth: 3
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, sanitiz =TRUE, fig.width=5, fig.height=3)
```

```{r}
library(tidyr)
library(dplyr)
library(pwr)
library(rjson)
library(ggplot2)
library(ggthemes)
library(entropy)
library(grid)
theme_new <- theme_set(theme_stata(scheme='s1rcolor', base_size=24))

# for bootstrapping 95% confidence intervals
theta <- function(x,xdata) {mean(xdata[x])}
theta.n <- function(x,xdata) {length(xdata[x])}
ci.low.n <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.n,x)$thetastar,.025)}
ci.high.n <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.n,x)$thetastar,.975)}
ci.low <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta,x)$thetastar,.025)}
ci.high <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta,x)$thetastar,.975)}
theta.s <- function(x,xdata) {sum(xdata[x])}
ci.low.s <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.s,x)$thetastar,.025)}
ci.high.s <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.s,x)$thetastar,.975)}
theta.neg <- function(x,xdata) {sum(!xdata[x])}
ci.low.neg <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.neg,x)$thetastar,.025)}
ci.high.neg <- function(x) {
  quantile(bootstrap::bootstrap(1:length(x),1000,theta.neg,x)$thetastar,.975)}

options(digits=3)
```

# Experiment

The narrative cloze task is a common evaluation task for script induction. I would like to understand humans' performance on the narrative cloze task.

In this task, participants read stories involving a particular entity. One of the events the entity is involved in is left blank. Participants are asked to fill in this blank with a plausible completion.

```{r}
raw.data.path <- "../data-processing/experiment1/"
all.data <- data.frame()
files <- dir(raw.data.path,pattern="*.json")

for (file.name in files) {
  json_file <- readLines(paste(raw.data.path,file.name,sep=""))
  json_file_str = paste(json_file, collapse = "")
  json_file_str = gsub(",}", "}", json_file_str)
  jso = jsonlite::fromJSON(json_file_str)
  trials = jso$trials
  demographics = jso$demographics
  for (i in 1:(nrow(demographics))) {
    trials[demographics[i,'qtype']] = demographics[i, 'response']
  }
  jso1 <- data.frame(trials)

  all.data <- rbind(all.data, jso1)
}

all.data = all.data %>% mutate(workerid = factor(as.numeric(factor(workerid))),
                               minutes = as.numeric(minutes))
```

## Demographics and attention checks

<!--

Comments:

```{r}
print(unique(all.data$comments))
```

Participants thought the study was about:


```{r}
print(unique(all.data$studyQuestionGuess))
```

-->


```{r}
completion.time = all.data %>% group_by(workerid) %>% summarise(minutes = mean(minutes)) %>% as.data.frame
attention.checks = all.data %>% group_by(workerid) %>% summarise(attention.check = response[chain=='attention']=='apples') %>% as.data.frame
good.Ss = attention.checks$workerid[attention.checks$attention.check]
```

Average completion time was `r round(mean(completion.time$minutes))` minutes.

`r length(unique(all.data$workerid)) - length(good.Ss)` participants were excluded for failing an attention check.

## Results

```{r}
# d = all.data %>% filter(workerid %in% good.Ss & chain!='attention') %>%
#   select(workerid, document, chain, clozeIndex, original, response,
#          original.head, response.head, trialnum) %>%
#   mutate(identical = original==response,
#          match = original.head==response.head,
#          document = factor(document),
#          chain = factor(chain),
#          clozeIndex = as.numeric(clozeIndex),
#          tag = paste(document, chain, clozeIndex))
# write.csv(d, 'data-raw.csv')
d = read.csv('data-annotated.csv') %>% mutate(manual.match = ifelse(manual.match=='yes', T, F))
```

How did people do, when we analyze their responses automatically?

```{r}
rbind(
  d %>% group_by(tag) %>%
    summarise(percent_correct = mean(match)) %>%
    summarise(high = ci.high(percent_correct),
              low = ci.low(percent_correct),
              mean_percent_correct = mean(percent_correct),
              version = 'auto'),
  d %>% group_by(tag) %>%
    summarise(percent_correct = mean(manual.match)) %>%
    summarise(high = ci.high(percent_correct),
              low = ci.low(percent_correct),
              mean_percent_correct = mean(percent_correct),
              version = 'hand')) %>%
  mutate(version = factor(version, levels=c('auto', 'hand'),
                          labels=c('Automatically Merged', 'Hand Annotated'))) %>%
  ggplot(aes(x=version, y=mean_percent_correct, fill=version, colour=version)) +
  geom_bar(stat='identity') +
  ylim(0, 1) +
  geom_errorbar(aes(x=version, ymin=low, ymax=high), width=0.05) +
  scale_fill_brewer(type='qual', palette = 6) +
  scale_colour_brewer(type='qual', palette = 4)
ggsave('human-compare-annotation.png', width=10, height=6)
```

For each word people said, how often did they say it?

```{r}
# N_per_tag = d %>% group_by(tag) %>% summarise(N = length(response))
# compare = d %>% group_by(tag, gloss) %>%
#   summarise(percent_people = length(gloss)/N_per_tag$N[N_per_tag$tag==tag[1]]) %>%
#   as.data.frame
# write.csv(compare, 'compare-before-ranks.csv')
model.ranks = read.csv('compare.csv')
model.ranks %>% group_by(tag) %>% summarise(rank = rank.orig[1]) %>%
  summarise(high = ci.high(rank),
            low = ci.low(rank),
            mean_rank = mean(rank)) %>%
  ggplot(aes(x=1, y=mean_rank)) +
  ylab('mean rank of actual word') +
  xlab('model') +
  geom_bar(stat='identity', fill='chartreuse4') +
  ylim(0, 1533) +
  geom_errorbar(aes(x=1, ymin=low, ymax=high), colour='chartreuse3', width=0.05)
ggsave('model.png', width=5, height=6)
```

```{r}
model.ranks = read.csv('compare.csv')
N_per_tag = model.ranks %>% group_by(tag) %>% summarise(N = length(gloss))

model.ranks %>% group_by(tag, gloss) %>%
  filter(rank.orig < 1000) %>%
  summarise(percent_people = length(gloss)/N_per_tag$N[N_per_tag$tag==tag][1],
            rank.orig = rank.orig) %>%
  ggplot(aes(x=percent_people, y=rank.orig)) +
  geom_point(colour='white')
ggsave('compare.png', width=10, height=6)
```

# References